{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fuy79Sq566S5"
   },
   "outputs": [],
   "source": [
    "# # IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
    "# # RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
    "# import kagglehub\n",
    "# kagglehub.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RB05xlAe66S6"
   },
   "outputs": [],
   "source": [
    "# # IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# # THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# # NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# # ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# # NOTEBOOK.\n",
    "\n",
    "# ariel_data_challenge_2024_path = kagglehub.competition_download('ariel-data-challenge-2024')\n",
    "# gordonyip_baseline_img_path = kagglehub.dataset_download('gordonyip/baseline-img')\n",
    "# gordonyip_binned_dataset_v3_path = kagglehub.dataset_download('gordonyip/binned-dataset-v3')\n",
    "\n",
    "# print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "was4_fLE66S7"
   },
   "source": [
    "# ADC 2024 starter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykfF7aVE66S8"
   },
   "source": [
    "This baseline notebook is designed to offer a starting point for the competiters. Please note that the approach we've taken is not *THE* solution — it's simply ONE possible approach. Our aim is to assist participants in exploring different ways to preprocess and model the data. Please feel free to fork the notebook and save the model/data for your own exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5TtuMXK66S8"
   },
   "source": [
    "This notebook was prepared by Virginie Batista and Angèle Syty from the Institut d'Astrophysique de Paris, and Orphée Faucoz from Centre National d’Etudes Spatiales (CNES), with support from Gordon Yip and Tara Tahseen from University College London."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyhFAoSk66S9"
   },
   "source": [
    "# READ THIS BEFORE YOU PROCEED\n",
    "This training procedure uses the light dataset produced from this [notebook (Version 5)](https://www.kaggle.com/code/gordonyip/update-calibrating-and-binning-astronomical-data). We applied all the calibration steps EXCEPT Linearity Correction with Chunksize = 1. The binned dataset is available to download [here](https://www.kaggle.com/datasets/gordonyip/binned-dataset-v3/data). *If you want to carry out all the correction, you will have to do so yourself.*\n",
    "\n",
    "\n",
    "**This notebook will only provide the model checkpoints, you are welcomed to use these checkpoints with your own script and submit to the leaderboard.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qj8A0u2R66S9"
   },
   "source": [
    "## Task overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1-ye_gZ66S-"
   },
   "source": [
    "The challenge's primary objective is to process these exposures to produce a single, clean spectrum for each exoplanet, summarizing the rp/rs values across all wavelengths.\n",
    "\n",
    "The exposure are subject to noises and the images or spectrum are not perfect. The Jitter noise has a complex signature that the ML model should recognize to produce a better spectra.\n",
    "\n",
    "Different techniques are possible and are up to the participant imagination to produce a novel (and hopefully better) solution to this task.\n",
    "\n",
    "Here outline our baseline approach :\n",
    "\n",
    "We first fit  a 1D CNN to fit the mean value of the transmission spectra, taking as input the transit white curve (total flux of each image taken as a function of time).\n",
    "\n",
    "For the second part of the baseline, to retrieve the atmopsheric features, we make the data lighter by summing up the fluxes along the y-axis, for each wavelength, resulting in 2D images of dimension (N_times, N_wavelengths). We also cut the signal to remove the out of transit in order to enhance transit depth variations between wavelengths. For the same reason, we substract the mean flux, corresponding to the average transit depth, to keep only wavelength variations around this mean. We use a 2D CNN to fit the atmospheric features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:17:01.078153Z",
     "iopub.status.busy": "2024-08-28T10:17:01.0771Z",
     "iopub.status.idle": "2024-08-28T10:17:01.637171Z",
     "shell.execute_reply": "2024-08-28T10:17:01.636235Z",
     "shell.execute_reply.started": "2024-08-28T10:17:01.078118Z"
    },
    "id": "9RHNHF0M66S-"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = mpimg.imread('/kaggle/input/baseline-img/2nd_baseline.png')\n",
    "plt.figure(figsize=(10, 15))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJXjYrRJ66S_"
   },
   "source": [
    "# Import library\n",
    "<a id=\"import\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:17:01.639779Z",
     "iopub.status.busy": "2024-08-28T10:17:01.63908Z",
     "iopub.status.idle": "2024-08-28T10:17:06.735786Z",
     "shell.execute_reply": "2024-08-28T10:17:06.73464Z",
     "shell.execute_reply.started": "2024-08-28T10:17:01.639737Z"
    },
    "id": "i1wvjJSL66S_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooh4BH6u66S_"
   },
   "source": [
    "# Setup Paths and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:17:06.737642Z",
     "iopub.status.busy": "2024-08-28T10:17:06.737044Z",
     "iopub.status.idle": "2024-08-28T10:17:06.74274Z",
     "shell.execute_reply": "2024-08-28T10:17:06.741434Z",
     "shell.execute_reply.started": "2024-08-28T10:17:06.737609Z"
    },
    "id": "71XNEnp266TA"
   },
   "outputs": [],
   "source": [
    "data_folder = '/kaggle/input/binned-dataset-v3/' # path to the folder containing the data\n",
    "auxiliary_folder = '/kaggle/input/ariel-data-challenge-2024/' # path to the folder containing the train targets and wavelengths informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:17:06.746468Z",
     "iopub.status.busy": "2024-08-28T10:17:06.746005Z",
     "iopub.status.idle": "2024-08-28T10:17:54.016348Z",
     "shell.execute_reply": "2024-08-28T10:17:54.014985Z",
     "shell.execute_reply.started": "2024-08-28T10:17:06.746432Z"
    },
    "id": "QcTDNxoM66TA"
   },
   "outputs": [],
   "source": [
    "data_train = np.load(f'{data_folder}/data_train.npy')\n",
    "data_train_FGS = np.load(f'{data_folder}/data_train_FGS.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qX-XiI5j66TA"
   },
   "source": [
    "We create a directory to save the outputs of this notebook, and define the hyperparameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:17:54.0182Z",
     "iopub.status.busy": "2024-08-28T10:17:54.017791Z",
     "iopub.status.idle": "2024-08-28T10:17:54.025061Z",
     "shell.execute_reply": "2024-08-28T10:17:54.024063Z",
     "shell.execute_reply.started": "2024-08-28T10:17:54.018159Z"
    },
    "id": "uhZXpS3666TA"
   },
   "outputs": [],
   "source": [
    "output_dir = './output'\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "do_the_mcdropout_wc = True\n",
    "do_the_mcdropout = True\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Directory {output_dir} created.\")\n",
    "else:\n",
    "    print(f\"Directory {output_dir} already exists.\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5wLzuQ966TA"
   },
   "source": [
    "# 1D-CNN for mean transit depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gy6wW0FW66TB"
   },
   "source": [
    "## Preprocessing for 1D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:17:54.027011Z",
     "iopub.status.busy": "2024-08-28T10:17:54.026564Z",
     "iopub.status.idle": "2024-08-28T10:17:54.081333Z",
     "shell.execute_reply": "2024-08-28T10:17:54.080197Z",
     "shell.execute_reply.started": "2024-08-28T10:17:54.026977Z"
    },
    "id": "tckFkj4H66TB"
   },
   "outputs": [],
   "source": [
    "train_solution = np.loadtxt(f'{auxiliary_folder}/train_labels.csv', delimiter = ',', skiprows = 1)\n",
    "\n",
    "targets = train_solution[:,1:]\n",
    "targets_mean = targets[:,1:].mean(axis = 1) # used for the 1D-CNN to extract the mean value, only AIRS wavelengths as the FGS point is not used in the white curve\n",
    "N = targets.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lPHk66j66TB"
   },
   "source": [
    "We create the dataset by adding the FGS frame, crushed in one column, at the end of the AIRS data cube.  \n",
    "The images are normalized using the star spectrum extracted from the images themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:17:54.083058Z",
     "iopub.status.busy": "2024-08-28T10:17:54.082729Z",
     "iopub.status.idle": "2024-08-28T10:17:59.166878Z",
     "shell.execute_reply": "2024-08-28T10:17:59.166052Z",
     "shell.execute_reply.started": "2024-08-28T10:17:54.083031Z"
    },
    "id": "jKWIOD6T66TB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "signal_AIRS_diff_transposed_binned, signal_FGS_diff_transposed_binned  = data_train, data_train_FGS\n",
    "FGS_column = signal_FGS_diff_transposed_binned.sum(axis = 2)\n",
    "dataset = np.concatenate([signal_AIRS_diff_transposed_binned, FGS_column[:,:, np.newaxis,:]], axis = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMNJhTwL66TB"
   },
   "source": [
    "we sum up the pixels on the y-axis to transform the data into 2D images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:17:59.168382Z",
     "iopub.status.busy": "2024-08-28T10:17:59.16807Z",
     "iopub.status.idle": "2024-08-28T10:18:01.065755Z",
     "shell.execute_reply": "2024-08-28T10:18:01.06485Z",
     "shell.execute_reply.started": "2024-08-28T10:17:59.168356Z"
    },
    "id": "RSMd4MtY66TB"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.sum(axis=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lT2SMapc66TC"
   },
   "source": [
    "We divide the images by the star flux assuming the first and last 50 instants belong to the out of transit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:18:01.067134Z",
     "iopub.status.busy": "2024-08-28T10:18:01.066858Z",
     "iopub.status.idle": "2024-08-28T10:18:01.188333Z",
     "shell.execute_reply": "2024-08-28T10:18:01.187533Z",
     "shell.execute_reply.started": "2024-08-28T10:18:01.067111Z"
    },
    "id": "oojaGjpq66TC"
   },
   "outputs": [],
   "source": [
    "def create_dataset_norm(dataset1, dataset2) :\n",
    "    dataset_norm1 = np.zeros(dataset1.shape)\n",
    "    dataset_norm2 = np.zeros(dataset1.shape)\n",
    "    dataset_min = dataset1.min()\n",
    "    dataset_max = dataset1.max()\n",
    "    dataset_norm1 = (dataset1 - dataset_min) / (dataset_max - dataset_min)\n",
    "    dataset_norm2 = (dataset2 - dataset_min) / (dataset_max - dataset_min)\n",
    "    return dataset_norm1, dataset_norm2\n",
    "\n",
    "\n",
    "def norm_star_spectrum (signal) :\n",
    "    img_star = signal[:,:50].mean(axis = 1) + signal[:,-50:].mean(axis = 1)\n",
    "    return signal/img_star[:,np.newaxis,:]\n",
    "\n",
    "dataset_norm = norm_star_spectrum(dataset)\n",
    "dataset_norm = np.transpose(dataset_norm,(0,2,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9as3E4I66TC"
   },
   "source": [
    "## Split the targets and observations between valid and train\n",
    "\n",
    "We start by computing a \"white curve\", that is actually the sum of the signal over the all image, as a function of time. We split the data and normalize the train/valid/test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:18:01.192606Z",
     "iopub.status.busy": "2024-08-28T10:18:01.192252Z",
     "iopub.status.idle": "2024-08-28T10:18:01.282142Z",
     "shell.execute_reply": "2024-08-28T10:18:01.281115Z",
     "shell.execute_reply.started": "2024-08-28T10:18:01.192577Z"
    },
    "id": "pso_iw9S66TC"
   },
   "outputs": [],
   "source": [
    "cut_inf, cut_sup = 39, 321 # we have previously cut the data along the wavelengths to remove the edges, this is to match with the targets range in the make data \n",
    "# file\n",
    "l = cut_sup - cut_inf + 1\n",
    "wls = np.arange(l)\n",
    "\n",
    "\n",
    "def split (data, N) :\n",
    "    list_planets = random.sample(range(0, data.shape[0]), N_train)\n",
    "    list_index_1 = np.zeros(data.shape[0], dtype = bool)\n",
    "    for planet in list_planets :\n",
    "        list_index_1[planet] = True\n",
    "    data_1 = data[list_index_1]\n",
    "    data_2 = data[~list_index_1]\n",
    "    return data_1, data_2, list_index_1\n",
    "\n",
    "N_train = 8*N//10\n",
    "\n",
    "# Validation and train data split\n",
    "train_obs, valid_obs, list_index_train = split(dataset_norm, N_train)\n",
    "train_targets, valid_targets = targets[list_index_train], targets[~list_index_train]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:18:01.283578Z",
     "iopub.status.busy": "2024-08-28T10:18:01.283252Z",
     "iopub.status.idle": "2024-08-28T10:18:02.718479Z",
     "shell.execute_reply": "2024-08-28T10:18:02.717674Z",
     "shell.execute_reply.started": "2024-08-28T10:18:01.283552Z"
    },
    "id": "bOUlYJX766TC"
   },
   "outputs": [],
   "source": [
    "signal_AIRS_diff_transposed_binned = signal_AIRS_diff_transposed_binned.sum(axis=3)\n",
    "wc_mean = signal_AIRS_diff_transposed_binned.mean(axis=1).mean(axis=1)\n",
    "white_curve = signal_AIRS_diff_transposed_binned.sum(axis=2)/ wc_mean[:, np.newaxis]\n",
    "\n",
    "def normalise_wlc(train, valid) :\n",
    "\n",
    "    wlc_train_min = train.min()\n",
    "    wlc_train_max = train.max()\n",
    "    train_norm = (train - wlc_train_min) / (wlc_train_max - wlc_train_min)\n",
    "    valid_norm = (valid - wlc_train_min) / (wlc_train_max - wlc_train_min)\n",
    "\n",
    "    return train_norm, valid_norm\n",
    "\n",
    "def normalize (train, valid) :\n",
    "    max_train = train.max()\n",
    "    min_train = train.min()\n",
    "    train_norm = (train - min_train) / (max_train - min_train)\n",
    "    valid_norm = (valid - min_train) / (max_train - min_train)\n",
    "    return train_norm, valid_norm, min_train, max_train\n",
    "\n",
    "# Split the light curves and targets\n",
    "train_wc, valid_wc = white_curve[list_index_train], white_curve[~list_index_train]\n",
    "train_targets_wc, valid_targets_wc = targets_mean[list_index_train], targets_mean[~list_index_train]\n",
    "\n",
    "# Normalize the wlc\n",
    "train_wc, valid_wc = normalise_wlc(train_wc, valid_wc)\n",
    "\n",
    "# Normalize the targets\n",
    "train_targets_wc_norm, valid_targets_wc_norm, min_train_valid_wc, max_train_valid_wc = normalize(train_targets_wc,\n",
    "                                                                                                 valid_targets_wc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:18:02.719855Z",
     "iopub.status.busy": "2024-08-28T10:18:02.719569Z",
     "iopub.status.idle": "2024-08-28T10:18:03.188177Z",
     "shell.execute_reply": "2024-08-28T10:18:03.187233Z",
     "shell.execute_reply.started": "2024-08-28T10:18:02.71983Z"
    },
    "id": "TpvPCClp66TD"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range (200) :\n",
    "    plt.plot(train_wc[-i], '-', alpha = 0.5)\n",
    "plt.title('Light-curves from the train set')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized flux')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBEimf1Z66TD"
   },
   "source": [
    "## Train 1D CNN\n",
    "The model to estimate the mean of the target spectrum using the white light-curve is a 1D-CNN with Dropout layers to make a MC Dropout prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:18:03.189684Z",
     "iopub.status.busy": "2024-08-28T10:18:03.189385Z",
     "iopub.status.idle": "2024-08-28T10:18:04.030675Z",
     "shell.execute_reply": "2024-08-28T10:18:04.029697Z",
     "shell.execute_reply.started": "2024-08-28T10:18:03.189658Z"
    },
    "id": "0wKqMLmt66TD"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, Concatenate,AveragePooling1D\n",
    "from keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "\n",
    "input_wc = Input((187,1))\n",
    "x = Conv1D(32, 3, activation='relu')(input_wc)\n",
    "x = MaxPooling1D()(x)\n",
    "x = BatchNormalization() (x)\n",
    "x = Conv1D(64, 3, activation='relu')(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Conv1D(128, 3, activation='relu')(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Conv1D(256, 3, activation='relu')(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(500, activation='relu')(x)\n",
    "x = Dropout(0.2)(x, training = True)\n",
    "x = Dense(100, activation='relu')(x)\n",
    "x = Dropout(0.1)(x, training = True)\n",
    "output_wc = Dense(1, activation='linear')(x)\n",
    "\n",
    "model_wc = Model(inputs=input_wc, outputs=output_wc)\n",
    "model_wc.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:18:04.032945Z",
     "iopub.status.busy": "2024-08-28T10:18:04.032106Z",
     "iopub.status.idle": "2024-08-28T10:20:58.861904Z",
     "shell.execute_reply": "2024-08-28T10:20:58.86087Z",
     "shell.execute_reply.started": "2024-08-28T10:18:04.032905Z"
    },
    "id": "1QnHivww66TD"
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    decay_rate = 0.2\n",
    "    decay_step = 200\n",
    "    if epoch % decay_step == 0 and epoch:\n",
    "        return lr * decay_rate\n",
    "    return lr\n",
    "\n",
    "optimizer = SGD(0.001)\n",
    "model_wc.compile(optimizer=optimizer, loss='mse', metrics=[MeanAbsoluteError()])\n",
    "callback = LearningRateScheduler(scheduler)\n",
    "checkpoint_filepath = 'output/model_1dcnn.keras'\n",
    "model_ckt = ModelCheckpoint(\n",
    "    checkpoint_filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"min\",\n",
    "    save_freq=\"epoch\",\n",
    ")\n",
    "\n",
    "print('Running ...')\n",
    "history = model_wc.fit(\n",
    "    x = train_wc,\n",
    "    y = train_targets_wc_norm,\n",
    "    validation_data = (valid_wc, valid_targets_wc_norm),\n",
    "    batch_size=16,\n",
    "    epochs= 1200,\n",
    "    shuffle=True,\n",
    "    verbose=0,\n",
    "    callbacks=[model_ckt]\n",
    "    )\n",
    "print('Done.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IH5lXj7q66TD"
   },
   "source": [
    "## 1D CNN Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:20:58.864384Z",
     "iopub.status.busy": "2024-08-28T10:20:58.863523Z",
     "iopub.status.idle": "2024-08-28T10:20:59.243754Z",
     "shell.execute_reply": "2024-08-28T10:20:59.242817Z",
     "shell.execute_reply.started": "2024-08-28T10:20:58.864344Z"
    },
    "id": "dExls2gQ66TE"
   },
   "outputs": [],
   "source": [
    "model_wc = load_model(checkpoint_filepath)\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O6-TGPX66TE"
   },
   "source": [
    "Then, we perform the MC Dropout to obtain the mean prediction and the uncertainty associated. We choose to compute 1000 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:20:59.245395Z",
     "iopub.status.busy": "2024-08-28T10:20:59.245086Z",
     "iopub.status.idle": "2024-08-28T10:22:06.348718Z",
     "shell.execute_reply": "2024-08-28T10:22:06.347692Z",
     "shell.execute_reply.started": "2024-08-28T10:20:59.245368Z"
    },
    "id": "yXqzH4su66TE"
   },
   "outputs": [],
   "source": [
    "nb_dropout_wc = 1000\n",
    "\n",
    "def unstandardizing (data, min_train_valid, max_train_valid) :\n",
    "    return data * (max_train_valid - min_train_valid) + min_train_valid\n",
    "\n",
    "def MC_dropout_WC (model, data, nb_dropout) :\n",
    "    predictions = np.zeros((nb_dropout, data.shape[0]))\n",
    "    for i in range(nb_dropout) :\n",
    "        predictions[i,:] = model.predict(data, verbose = 0).flatten()\n",
    "    return predictions\n",
    "\n",
    "if do_the_mcdropout_wc :\n",
    "    print('Running ...')\n",
    "    prediction_valid_wc = MC_dropout_WC(model_wc, valid_wc, nb_dropout_wc)\n",
    "    spectre_valid_wc_all = unstandardizing(prediction_valid_wc, min_train_valid_wc, max_train_valid_wc)\n",
    "    spectre_valid_wc, spectre_valid_std_wc = spectre_valid_wc_all.mean(axis = 0), spectre_valid_wc_all.std(axis = 0)\n",
    "    print('Done.')\n",
    "\n",
    "else :\n",
    "    spectre_valid_wc = model_wc.predict(valid_wc).flatten()\n",
    "    spectre_valid_wc = unstandardizing(spectre_valid_wc, min_train_valid_wc, max_train_valid_wc)\n",
    "    spectre_valid_std_wc = 0.1*np.abs(spectre_valid_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:06.350187Z",
     "iopub.status.busy": "2024-08-28T10:22:06.349899Z",
     "iopub.status.idle": "2024-08-28T10:22:07.161288Z",
     "shell.execute_reply": "2024-08-28T10:22:07.160204Z",
     "shell.execute_reply.started": "2024-08-28T10:22:06.350161Z"
    },
    "id": "b4m9kBG366TE"
   },
   "outputs": [],
   "source": [
    "residuals = spectre_valid_wc - valid_targets_wc\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 6), sharex=True,\n",
    "                               gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "ax1.errorbar(x = np.arange(len(spectre_valid_wc)), y = spectre_valid_wc, yerr =spectre_valid_std_wc, fmt = '.', color = 'k', ecolor = 'gray', label='Prediction', alpha=0.8)\n",
    "ax1.fill_between(np.arange(len(spectre_valid_wc)), spectre_valid_wc - spectre_valid_std_wc, spectre_valid_wc + spectre_valid_std_wc, color = 'grey', alpha = 0.5)\n",
    "ax1.vlines(np.arange(len(spectre_valid_wc)),ymin=0, ymax=spectre_valid_wc, colors='r', linestyle='dashed',alpha = 0.1)\n",
    "ax1.plot(valid_targets_wc, 'r.', label='Target', alpha=0.8)\n",
    "ax1.set_xlabel('Concatenated targets')\n",
    "ax1.set_ylabel('$(R_p/R_s)^2$')\n",
    "ax1.set_title('Prediction vs target, mean value of the spectrum, on validation dataset')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(residuals, 'b.', label='Residuals', alpha=0.8)\n",
    "ax2.set_xlabel('Concatenated targets')\n",
    "ax2.set_ylabel('Residuals')\n",
    "ax2.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:07.16275Z",
     "iopub.status.busy": "2024-08-28T10:22:07.162458Z",
     "iopub.status.idle": "2024-08-28T10:22:07.168677Z",
     "shell.execute_reply": "2024-08-28T10:22:07.167535Z",
     "shell.execute_reply.started": "2024-08-28T10:22:07.162727Z"
    },
    "id": "BakooHIo66TE"
   },
   "outputs": [],
   "source": [
    "residuals = valid_targets_wc - spectre_valid_wc\n",
    "print('MSE : ', np.sqrt((residuals**2).mean())*1e6, 'ppm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:07.17009Z",
     "iopub.status.busy": "2024-08-28T10:22:07.169736Z",
     "iopub.status.idle": "2024-08-28T10:22:07.180378Z",
     "shell.execute_reply": "2024-08-28T10:22:07.17937Z",
     "shell.execute_reply.started": "2024-08-28T10:22:07.170064Z"
    },
    "id": "PwGDQKBz66TF"
   },
   "outputs": [],
   "source": [
    "# np.save(f'{output_dir}/pred_valid_wc.npy', spectre_valid_wc)\n",
    "# np.save(f'{output_dir}/targ_valid_wc.npy', valid_targets_wc)\n",
    "# np.save(f'{output_dir}/std_valid_wc.npy', spectre_valid_std_wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1V0D5iD66TL"
   },
   "source": [
    "# 2D CNN for atmospheric features\n",
    "\n",
    "<a id=\"fluctu\"></a>\n",
    "We now remove the mean value (transit depth) of the spectra to keep the atmospheric features only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpqlv-EI66TL"
   },
   "source": [
    "## Preprocessing for 2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:07.182216Z",
     "iopub.status.busy": "2024-08-28T10:22:07.181654Z",
     "iopub.status.idle": "2024-08-28T10:22:07.192868Z",
     "shell.execute_reply": "2024-08-28T10:22:07.192006Z",
     "shell.execute_reply.started": "2024-08-28T10:22:07.182188Z"
    },
    "id": "iUrsXkXs66TL"
   },
   "outputs": [],
   "source": [
    "def suppress_mean(targets, mean) :\n",
    "    res = targets - np.repeat(mean.reshape((mean.shape[0], 1)), repeats = targets.shape[1], axis = 1)\n",
    "    return res\n",
    "train_targets, valid_targets = targets[list_index_train], targets[~list_index_train]\n",
    "\n",
    "train_targets_shift = suppress_mean(train_targets,  targets_mean[list_index_train])\n",
    "valid_targets_shift = suppress_mean(valid_targets,  targets_mean[~list_index_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WvY4LtI66TL"
   },
   "source": [
    "We normalize the targets so that they range between -1 and 1, centered on zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:07.195007Z",
     "iopub.status.busy": "2024-08-28T10:22:07.194238Z",
     "iopub.status.idle": "2024-08-28T10:22:07.20338Z",
     "shell.execute_reply": "2024-08-28T10:22:07.202373Z",
     "shell.execute_reply.started": "2024-08-28T10:22:07.194979Z"
    },
    "id": "5uuZGAjM66TL"
   },
   "outputs": [],
   "source": [
    "##### normalization of the targets ###\n",
    "def targets_normalization (data1, data2) :\n",
    "    data_min = data1.min()\n",
    "    data_max = data1.max()\n",
    "    data_abs_max = np.max([data_min, data_max])\n",
    "    data1 = data1/data_abs_max\n",
    "    data2 = data2/data_abs_max\n",
    "    return data1, data2, data_abs_max\n",
    "\n",
    "def targets_norm_back (data, data_abs_max) :\n",
    "    return data * data_abs_max\n",
    "\n",
    "train_targets_norm, valid_targets_norm, targets_abs_max = targets_normalization(train_targets_shift, valid_targets_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:07.205369Z",
     "iopub.status.busy": "2024-08-28T10:22:07.204723Z",
     "iopub.status.idle": "2024-08-28T10:22:07.990582Z",
     "shell.execute_reply": "2024-08-28T10:22:07.989574Z",
     "shell.execute_reply.started": "2024-08-28T10:22:07.205336Z"
    },
    "id": "zPpSUNNf66TM"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "for i in range (240) :\n",
    "    plt.plot(wls, train_targets_norm[i], 'g-', alpha = 0.5)\n",
    "plt.plot([], [], 'g-', alpha=0.5, label='Train targets')\n",
    "for i in range (60) :\n",
    "    plt.plot(wls, valid_targets_norm[i], 'r-', alpha = 0.7)\n",
    "plt.plot([], [], 'r-', alpha=0.5, label='Valid targets (true mean)')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(f'$(R_p/R_s)^2$')\n",
    "plt.title('All targets after substracting the mean value and normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:07.992971Z",
     "iopub.status.busy": "2024-08-28T10:22:07.992149Z",
     "iopub.status.idle": "2024-08-28T10:22:07.998457Z",
     "shell.execute_reply": "2024-08-28T10:22:07.99745Z",
     "shell.execute_reply.started": "2024-08-28T10:22:07.992933Z"
    },
    "id": "q-GJRdCn66TM"
   },
   "outputs": [],
   "source": [
    "###### Transpose #####\n",
    "train_obs = train_obs.transpose(0, 2, 1)\n",
    "valid_obs = valid_obs.transpose(0, 2, 1)\n",
    "print(train_obs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G347qJkF66TM"
   },
   "source": [
    "We cut the transit to keep the in-transit. We assume an arbitrary transit duration of 40 instants with a transit occuring between 75 and 115."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:08.000657Z",
     "iopub.status.busy": "2024-08-28T10:22:07.999784Z",
     "iopub.status.idle": "2024-08-28T10:22:08.008246Z",
     "shell.execute_reply": "2024-08-28T10:22:08.007517Z",
     "shell.execute_reply.started": "2024-08-28T10:22:08.000628Z"
    },
    "id": "u_UbR13A66TM"
   },
   "outputs": [],
   "source": [
    "##### Substracting the out transit signal #####\n",
    "def suppress_out_transit (data, ingress, egress) :\n",
    "    data_in = data[:, ingress:egress,:]\n",
    "    return data_in\n",
    "\n",
    "ingress, egress = 75,115\n",
    "train_obs_in = suppress_out_transit(train_obs, ingress, egress)\n",
    "valid_obs_in = suppress_out_transit(valid_obs, ingress, egress)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8bQzwgx66TM"
   },
   "source": [
    "We remove the mean value of the in-transit to get relative data like the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:08.00976Z",
     "iopub.status.busy": "2024-08-28T10:22:08.009383Z",
     "iopub.status.idle": "2024-08-28T10:22:08.080069Z",
     "shell.execute_reply": "2024-08-28T10:22:08.07925Z",
     "shell.execute_reply.started": "2024-08-28T10:22:08.009736Z"
    },
    "id": "PXCAyac966TM"
   },
   "outputs": [],
   "source": [
    "###### Substract the mean #####\n",
    "def substract_data_mean(data):\n",
    "    data_mean = np.zeros(data.shape)\n",
    "    for i in range(data.shape[0]):\n",
    "        data_mean[i] = data[i] - data[i].mean()\n",
    "    return data_mean\n",
    "\n",
    "train_obs_2d_mean = substract_data_mean(train_obs_in)\n",
    "valid_obs_2d_mean = substract_data_mean(valid_obs_in)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8W0lyxH66TN"
   },
   "source": [
    "We use the same normalization as for the targets, i.e. between -1 and 1 centered on zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:08.081484Z",
     "iopub.status.busy": "2024-08-28T10:22:08.08118Z",
     "iopub.status.idle": "2024-08-28T10:22:08.114991Z",
     "shell.execute_reply": "2024-08-28T10:22:08.11394Z",
     "shell.execute_reply.started": "2024-08-28T10:22:08.081458Z"
    },
    "id": "n4adys_c66TN"
   },
   "outputs": [],
   "source": [
    "##### Normalization dataset #####\n",
    "def data_norm(data1, data2):\n",
    "    data_min = data1.min()\n",
    "    data_max = data1.max()\n",
    "    data_abs_max = np.max([data_min, data_max])\n",
    "    data1 = data1/data_abs_max\n",
    "    data2 = data2/data_abs_max\n",
    "    return data1, data2, data_abs_max\n",
    "\n",
    "\n",
    "def data_normback(data, data_abs_max) :\n",
    "    return data * data_abs_max\n",
    "\n",
    "train_obs_norm, valid_obs_norm, data_abs_max = data_norm(train_obs_2d_mean, valid_obs_2d_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:08.116589Z",
     "iopub.status.busy": "2024-08-28T10:22:08.116263Z",
     "iopub.status.idle": "2024-08-28T10:22:10.439434Z",
     "shell.execute_reply": "2024-08-28T10:22:10.438411Z",
     "shell.execute_reply.started": "2024-08-28T10:22:08.116563Z"
    },
    "id": "fG7zX1Pq66TN"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for i in range (train_obs.shape[0]) :\n",
    "    plt.plot(wls, train_obs_norm[i,10], 'g-', alpha = 0.5)\n",
    "plt.plot([], [], 'g-', alpha=0.5, label='Train targets')\n",
    "for i in range (valid_obs.shape[0]) :\n",
    "    plt.plot(wls, valid_obs_norm[i,10], 'r-', alpha = 0.7)\n",
    "plt.plot([], [], 'r-', alpha=0.5, label='Valid targets (true mean)')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(f'$(R_p/R_s)^2$')\n",
    "plt.title('Train and Valid data after substracting the mean value and normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NW65zipT66TN"
   },
   "source": [
    "## Train 2D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:10.444641Z",
     "iopub.status.busy": "2024-08-28T10:22:10.444319Z",
     "iopub.status.idle": "2024-08-28T10:22:10.602608Z",
     "shell.execute_reply": "2024-08-28T10:22:10.601631Z",
     "shell.execute_reply.started": "2024-08-28T10:22:10.444614Z"
    },
    "id": "DbMNYPnD66TN"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Reshape, Dropout, BatchNormalization, AveragePooling2D\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "## CNN 2 global normalization data\n",
    "input_obs = Input((40,283,1))\n",
    "x = Conv2D(32, (3, 1), activation='relu', padding='same')(input_obs)\n",
    "x = MaxPooling2D((2, 1))(x)\n",
    "x = BatchNormalization() (x)\n",
    "x = Conv2D(64, (3, 1), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 1))(x)\n",
    "x = Conv2D(128, (3, 1), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 1))(x)\n",
    "x = Conv2D(256, (3, 1), activation='relu', padding='same')(x)\n",
    "x = Conv2D(32, (1, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((1, 2))(x)\n",
    "x = BatchNormalization() (x)\n",
    "x = Conv2D(64, (1, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((1, 2))(x)\n",
    "x = Conv2D(128, (1, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((1, 2))(x)\n",
    "x = Conv2D(256, (1, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((1, 2))(x)\n",
    "x = Flatten()(x)\n",
    "# DNN\n",
    "x = Dense(700, activation='relu')(x)\n",
    "x = Dropout(0.2)(x, training = True)\n",
    "output = Dense(283, activation='linear')(x)\n",
    "\n",
    "model = Model(inputs=[input_obs], outputs=output)\n",
    "\n",
    "checkpoint_filepath = 'output/model_2dcnn.keras'\n",
    "model_ckt2 = ModelCheckpoint(\n",
    "    checkpoint_filepath,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"min\",\n",
    "    save_freq=\"epoch\",\n",
    ")\n",
    "model.compile(optimizer=Adam(0.001), loss='mse', metrics=[MeanAbsoluteError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:22:10.604205Z",
     "iopub.status.busy": "2024-08-28T10:22:10.603843Z",
     "iopub.status.idle": "2024-08-28T10:24:56.643548Z",
     "shell.execute_reply": "2024-08-28T10:24:56.6424Z",
     "shell.execute_reply.started": "2024-08-28T10:22:10.604167Z"
    },
    "id": "mrE4aD9b66TO"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "     x = train_obs_norm,\n",
    "     y = train_targets_norm,\n",
    "     validation_data = (valid_obs_norm, valid_targets_norm),\n",
    "     batch_size=32,\n",
    "     epochs= 200,\n",
    "     shuffle=True,\n",
    "     verbose=0,\n",
    "    callbacks=[model_ckt2]\n",
    " )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzTP1vGq66TO"
   },
   "source": [
    "## Postprocessing and visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-MvTH1j66TO"
   },
   "source": [
    "We obtain uncertainties on the predictions by computing a MCDropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:24:56.646064Z",
     "iopub.status.busy": "2024-08-28T10:24:56.64575Z",
     "iopub.status.idle": "2024-08-28T10:24:58.094042Z",
     "shell.execute_reply": "2024-08-28T10:24:58.092907Z",
     "shell.execute_reply.started": "2024-08-28T10:24:56.646036Z"
    },
    "id": "JQFtBOR166TO"
   },
   "outputs": [],
   "source": [
    "nb_dropout = 5\n",
    "\n",
    "def NN_uncertainity(model, x_test, targets_abs_max, T=5):\n",
    "    predictions = []\n",
    "    for _ in range(T):\n",
    "        pred_norm = model.predict([x_test],verbose=0)\n",
    "        pred = targets_norm_back(pred_norm, targets_abs_max)\n",
    "        predictions += [pred]\n",
    "    mean, std = np.mean(np.array(predictions), axis=0), np.std(np.array(predictions), axis=0)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "if do_the_mcdropout :\n",
    "    spectre_valid_shift, spectre_valid_shift_std = NN_uncertainity(model, [valid_obs_norm], targets_abs_max, T = nb_dropout)\n",
    "\n",
    "else :\n",
    "\n",
    "    pred_valid_norm = model.predict([valid_obs_norm])\n",
    "    pred_valid = targets_norm_back(pred_valid_norm, targets_abs_max)\n",
    "    spectre_valid_shift = pred_valid\n",
    "    spectre_valid_shift_std = spectre_valid_shift*0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:24:58.095552Z",
     "iopub.status.busy": "2024-08-28T10:24:58.095232Z",
     "iopub.status.idle": "2024-08-28T10:24:58.101838Z",
     "shell.execute_reply": "2024-08-28T10:24:58.100803Z",
     "shell.execute_reply.started": "2024-08-28T10:24:58.095524Z"
    },
    "id": "dTBR2BKA66TO"
   },
   "outputs": [],
   "source": [
    "residuals = valid_targets_shift - spectre_valid_shift\n",
    "print('MSE : ', np.sqrt((residuals**2).mean())*1e6, 'ppm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:24:58.103358Z",
     "iopub.status.busy": "2024-08-28T10:24:58.103053Z",
     "iopub.status.idle": "2024-08-28T10:24:58.112147Z",
     "shell.execute_reply": "2024-08-28T10:24:58.111179Z",
     "shell.execute_reply.started": "2024-08-28T10:24:58.103327Z"
    },
    "id": "tvbLd4lB66TP"
   },
   "outputs": [],
   "source": [
    "# np.save(f'{output_dir}/pred_valid_shift.npy', spectre_valid_shift)\n",
    "# np.save(f'{output_dir}/targ_valid_shift.npy', valid_targets_shift)\n",
    "# np.save(f'{output_dir}/std_valid_shift.npy', spectre_valid_shift_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:24:58.113854Z",
     "iopub.status.busy": "2024-08-28T10:24:58.113246Z",
     "iopub.status.idle": "2024-08-28T10:24:58.460699Z",
     "shell.execute_reply": "2024-08-28T10:24:58.459616Z",
     "shell.execute_reply.started": "2024-08-28T10:24:58.113828Z"
    },
    "id": "KFaDhFvw66TP"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range (50) :\n",
    "    plt.plot(spectre_valid_shift[-i]+0.0001*i, '-', alpha = 0.5)\n",
    "plt.title('Spectra predictions for the validation set')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Arbitrary flux')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:24:58.462615Z",
     "iopub.status.busy": "2024-08-28T10:24:58.462279Z",
     "iopub.status.idle": "2024-08-28T10:24:59.960337Z",
     "shell.execute_reply": "2024-08-28T10:24:59.959345Z",
     "shell.execute_reply.started": "2024-08-28T10:24:58.462586Z"
    },
    "id": "rIpkBDLd66TP"
   },
   "outputs": [],
   "source": [
    "list_valid_planets = [0, 12, 35, 60, 70]\n",
    "wavelength = np.loadtxt('/kaggle/input/ariel-data-challenge-2024/wavelengths.csv', skiprows=1, delimiter = ',')\n",
    "uncertainty = spectre_valid_shift_std\n",
    "for i in (list_valid_planets):\n",
    "    plt.figure()\n",
    "    plt.title('Result for the sample {} of the validation set'.format(i))\n",
    "    plt.plot(wavelength, spectre_valid_shift[i], '.k', label = 'Prediction')\n",
    "    plt.plot(wavelength, valid_targets_shift[i], color = 'tomato', label = 'Target')\n",
    "    plt.fill_between(wavelength, spectre_valid_shift[i] - spectre_valid_shift_std[i], spectre_valid_shift[i] + spectre_valid_shift_std[i], color='silver', alpha = 0.8, label = 'Uncertainty')\n",
    "    plt.legend()\n",
    "    plt.ylabel(f'$(R_p/R_s)^2$')\n",
    "    plt.xlabel(f'Wavelength ($\\mu$m)')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKrpHlnl66TP"
   },
   "source": [
    "# Combine 1D and 2D CNN output for FINAL SPECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:24:59.961854Z",
     "iopub.status.busy": "2024-08-28T10:24:59.961581Z",
     "iopub.status.idle": "2024-08-28T10:24:59.96746Z",
     "shell.execute_reply": "2024-08-28T10:24:59.966488Z",
     "shell.execute_reply.started": "2024-08-28T10:24:59.96183Z"
    },
    "id": "Ski6to8766TP"
   },
   "outputs": [],
   "source": [
    "######## ADD THE FLUCTUATIONS TO THE MEAN ########\n",
    "def add_the_mean (shift, mean) :\n",
    "    return shift + mean[:,np.newaxis]\n",
    "\n",
    "predictions_valid = add_the_mean(spectre_valid_shift,spectre_valid_wc)\n",
    "\n",
    "predictions_std_valid = np.sqrt(spectre_valid_std_wc[:,np.newaxis]**2 + spectre_valid_shift_std**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:24:59.969454Z",
     "iopub.status.busy": "2024-08-28T10:24:59.96877Z",
     "iopub.status.idle": "2024-08-28T10:25:03.140594Z",
     "shell.execute_reply": "2024-08-28T10:25:03.139626Z",
     "shell.execute_reply.started": "2024-08-28T10:24:59.969419Z"
    },
    "id": "piWbWjUv66TQ"
   },
   "outputs": [],
   "source": [
    "uncertainty = predictions_std_valid\n",
    "\n",
    "def plot_one_sample_valid(ax, p):\n",
    "    ax.set_title(f'Result for sample {p} ')\n",
    "    line1, = ax.plot(wavelength, predictions_valid[p], '.k', label='Prediction')\n",
    "    line2, = ax.plot(wavelength, valid_targets[p], color='tomato', label='Target')\n",
    "    ax.fill_between(wavelength, predictions_valid[p, :] - uncertainty[p], predictions_valid[p, :] + uncertainty[p], color='silver', alpha=0.8, label='Uncertainty')\n",
    "    ax.set_ylabel(f'$(R_p/R_s)^2$')\n",
    "    ax.set_xlabel(f'Wavelength ($\\mu$m)')\n",
    "    return line1, line2\n",
    "\n",
    "\n",
    "num_samples = 16\n",
    "rows, cols = 4, 4\n",
    "\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(15, 10))\n",
    "samples = [1, 2, 7, 15, 20, 25, 30, 35, 40, 45, 50, 55, 6, 5, 8, 9]\n",
    "lines = []\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    lines.extend(plot_one_sample_valid(ax, samples[i]))\n",
    "\n",
    "fig.legend(lines[:2], ['Prediction', 'Target'], loc='upper center', ncol=3, bbox_to_anchor=(0.5, -0.05))\n",
    "fig.suptitle('Validation dataset')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:25:03.142266Z",
     "iopub.status.busy": "2024-08-28T10:25:03.14191Z",
     "iopub.status.idle": "2024-08-28T10:25:04.306814Z",
     "shell.execute_reply": "2024-08-28T10:25:04.305898Z",
     "shell.execute_reply.started": "2024-08-28T10:25:03.142235Z"
    },
    "id": "XbpIHdSD66TQ"
   },
   "outputs": [],
   "source": [
    "######## PLOTS THE RESULT ########\n",
    "predictions = predictions_valid\n",
    "targets_plot = valid_targets\n",
    "std = predictions_std_valid\n",
    "\n",
    "predictions_concatenated_plot = np.concatenate(predictions, axis=0)\n",
    "wls_concatenated = np.arange(predictions_concatenated_plot.shape[0])\n",
    "targets_concatenated_plot = np.concatenate(targets_plot, axis=0)\n",
    "spectre_valid_std_concatenated = np.concatenate(std, axis=0)\n",
    "residuals = targets_concatenated_plot - predictions_concatenated_plot\n",
    "uncertainty = spectre_valid_std_concatenated\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(9, 8), gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "\n",
    "axs[0].plot(wls_concatenated, predictions_concatenated_plot, '-', color='k', label=\"Prediction\")\n",
    "axs[0].plot(wls_concatenated, targets_concatenated_plot, '-', color='tomato', label=\"Target\")\n",
    "axs[0].fill_between(np.arange(len(wls_concatenated)),\n",
    "                    predictions_concatenated_plot - uncertainty,\n",
    "                    predictions_concatenated_plot + uncertainty,\n",
    "                    color='silver', alpha=1, label='Uncertainty')\n",
    "axs[0].set_xlabel('Concatenated wavelengths for all planets')\n",
    "axs[0].set_ylabel(f'$(R_p/R_s)^2$')\n",
    "axs[0].set_title('Prediction vs target, validation dataset')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(wls_concatenated, residuals, '-', color='cornflowerblue', label=\"Residual\")\n",
    "axs[1].fill_between(np.arange(len(wls_concatenated)),\n",
    "                    residuals - uncertainty,\n",
    "                    residuals + uncertainty,\n",
    "                    color='lightblue', alpha=0.9, label='Uncertainty')\n",
    "axs[1].set_xlabel('Concatenated wavelengths for all planets')\n",
    "axs[1].set_ylabel('Residual')\n",
    "axs[1].set_title('Residuals with Uncertainty')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('MSE : ',np.sqrt((residuals**2).mean())*1e6, 'ppm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T10:25:04.308233Z",
     "iopub.status.busy": "2024-08-28T10:25:04.307962Z",
     "iopub.status.idle": "2024-08-28T10:25:04.312201Z",
     "shell.execute_reply": "2024-08-28T10:25:04.311269Z",
     "shell.execute_reply.started": "2024-08-28T10:25:04.308209Z"
    },
    "id": "S2VkPQnq66TQ"
   },
   "outputs": [],
   "source": [
    "# np.save(f'{output_dir}/pred_valid.npy', predictions_valid)\n",
    "# np.save(f'{output_dir}/std_valid.npy', predictions_std_valid)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9188054,
     "sourceId": 70367,
     "sourceType": "competition"
    },
    {
     "datasetId": 5498833,
     "sourceId": 9110664,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5546655,
     "sourceId": 9177563,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
